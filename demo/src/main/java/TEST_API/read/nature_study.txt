1.음절과 형태소 , 어절이 무엇인지 설명하고 차이점을 기술하시오
2.품사의 대분류를 간략하게 설명하시오
3.다음 문장들의 의존 구조를 그리시오
 나는 학교에 갔다
 철수는 새로운 일을 시작했다
4.MLE 와 MAP 의 차이를 서술하시오


자연어 처리(natural language processing NLP)
자연어에 대한 공학적 분석 처리하는 것
 : 교정,텍스트분류(태그,스팸 등),정보추출,질의(쳇봇),기계번역,검색,요약,거대언어모델(GPT) 등
처리 2단계
소스언어(자연어) -> 자연어 이해(NLU) -> C -> 자연어 생성(NLG) -> 타겟언어(자연어)

자연어처리의 방해요소
언어의중의성, 규칙예외, 유연성
중의성 : 단어 - 배, 이 등  문장 - Stolen painting was found by tree 트리에 있었다, 트리에 의해 발견했다.
규칙예외 :  복수표현 - s,es 가 아닌 다른 단어 child,children, fish,fish 등 
           시제표현 - ed가 아닌 다른 단어 eat,ate run,ran 등
           의미변화 - 문법에 따라 뜻이 달라짐 hit the sack -잠들다 , hit the brown sack - 갈색자룰 때리다.
“All grammars leak” - 언어의 입체성과 오용
유연성 : 신조어,의미(지식)의 변조,상황에 따라 달라짐(내새끼-강아지,사람 강아지 -사람,개)
         숙어(눈엣가시,물먹다-망함,물섭취), 비문법적 언어사용(드뎌긱사서만쥬팜)


언어학의 연구패러다임
2가지 접근법
이성주의 : 언어는 뇌에 내저적으로 습되어있어 규칙성을 가지고 이런 규칙성을 찾아야 함 - 규칙기반 처리
경험주의 : 언어는 외부적 자극으로 습득 외부 자원을 활용해 언어 형상을 규명 - 말뭉치 기반 연구

규칙기반 처리방법
: 언어의 문법적인 규칙을 사전에 찾아 규칙에 맞춰 자연어 처리 - 모든 규칙을 구축하기 어려움
ex) 밤에 대하여 - if 맛있다,먹다 포함되면 과일 밤 , 앞뒤어절에 어둡다 밝다가 포함되면 하루의 밤 
    멀리있는 어절 모든 어절에 대한 규칙 설정이 어려움.

말뭉치기반 처리방법(통계,기계학습,인공신경망)
: 문장을 단어별로 나누어 특정 단어의 앞이나 뒤에올 단어를 확률적으로 계산 언어의 규칙이 있을시 유의미한 상관관계가 있다는 가정
ex) 빈칸단어 에측 - 나는 옷가게에서 ?를 샀다 -> 옷이 확률상 높음 등
    밤이 어두워져 ~를 했다 -> 어둡다 등 단어의 사용빈도수로 확률 계산하여 밤의 의미를 정함.
: 모델을 학습하기 위해 많은 외부데이터(말뭉치)를 이용해 학습된 모델(통계)을 생성함
  품사태깅 - Hidden Markov Model, Conditional Random Fields
: 뇌의 신경계를 구조화 시킨 모델 화살표로 가중치 설정 입력층,은닉층,출력층으로 구성
  RNN, Transformer, Word2Vec,  Pre trained Language Model (Bert, Roberta, GPT 등)

1.자연어를 규칙으로 처리하기 어려운 이유는 무엇인가
: 자연어 처리에는 방해요소가 존재하며 방해요소로 인해 언어의 이해,생성시 사용되는 로직에 대한 많은 예외사항 발생
  대표적인 방해요소는 언어의중의성,규칙예외,유연성이 있음.
2.언어학의 학문적 접근 방법인 이성주의와 경험주의 방법은 어떤 차이가 있는가
: 뇌 내에 이미 습득된 규칙성이 존재한다는 이성주의 접근과 외부적 자극으로 습득한 외부자원을 활용해 언어현상을
  규명한다는 접근적인 차이가 존재함. 이성주의 방법은 규칙기반 처리방법을 가지며 경험주의 방법은 말뭉치기반 처리방법을ㅇ
  이용하여 연구한다는 차이가 있음.
3.모호성이 있는 문장 5 개를 예를 들고 , 그 이유를 설명하시오
: 
4.복합명사중 분리가 잘못되면 의미가 달라지는 단어 5 개를 들고 , 각각의 분리 방법을 적으시오
5.최근 발표되고 있는 Chat Bot 들을 조사하고 , 간단한 특징을 적으시오


음절
가장작은 발화단위 - 자음(초성,종성),모음(중성)
이때, 한국어 자연어처리에서는 한글자 단위를 음절이라고 함(초+중+(종))
어절
한개 이상의 형태소가 모여 만들어지는 단위 
한국어 자연어 처리에서는 띄어쓰기가 기준 (영어는 단어)
형태소
의미를 가지는 가장 작은 단위 - 실질,형식 형태소로 나눔
실질형태소 - 어휘형태소로 나,학교,좋- 등 실질적 의미를 갖는 형태소
형식형태소 - 문법형태소 -는,-가,-다 등 문법적인 기능을 갖는 형태소
품사
문장에서 가장 작은 형태소가 수행하는 역할을 분류 - 체언,수식언,관계언,독립언,용언 - 작은단위 : 명사,형용사,동사 등
불변어 - 사용할 때 단어의 형태가 변하지 않음 : 체언,수식언,관계언,독립언 (동사,형용사제외 전부)
가변어 - 사용할 때 단어의 형태가 변함 : 용언 (동사,형용사) - 멋지다,멋진 아름답다,아름다운

체언 - 명사(사과),대명사(나,너,우리),수사(첫째) 단독으로도 쓰이고 조사랑도 같이 쓰임 
수식언 - 관형사(그,옛,한,두),부사(매우,잘,내일,또는)
관계언 - 자립 형태소에 붙어 문법적 관계 나타내는 의존형태소 (의,을,이,가)
독립언 - 독립적으로 쓰이는 수식이 없는 품사 문장에서의 위치가 비교적 자유로움 (아이고,그래)
용언 - 독립된 뜻 어미를 활용하여 문장에서 서술어 기능을 함. 어간과 어미로 이루어짐 
       어간 : 하나 또는 둘 이상의 어근 결합 또는 접사에 의해 파상 (이러-한,비롯-된,심각-하게)
       어미 : 어간에 붙어 문법적 의미표현 (종결,연결,전성,선어말 어미 등 - -였,-겠,-었 -ㄴ 등)

구구조 - 방식 체크 필요
언어분석에 주로 이용되며, 문장을 구성하고 있는 요소들이 한 덩어리 단위로 형성되는 일정한 구조
영어는 명사구-동사구로 나누어 볼 수 있음(Noun Phrase, Verb Phrase) 구구조에서 문장은 수형도로 나타낼 수 있음

의존구조 - 방식 체크 필요
단어간 의존관계를 통해 구문을 이룬다고보는 관점 각 단어를 지배소,의존소로 나누어 분석

의미론
단어,문장,발화에서 표현이 실제로 가리키는 지시체와의 의미관계 파악 
(사료가 개를 먹었습니다)
의미역 - ""명사""의 다양한 역할을 설명
Agent : 어떤 행동을 의도를 가지고 행하는 객체 -> 행위주체
Patient : 행동에 영향을 받는 객체 -> 행위대상
Instrument : 행동을 수행하는데 사용되는 객체 -> 행위수단
Location : 행동이 수행되는 장소 -> 행위장소 
ex) 철수는 강단에서 영희에게 꽃을 주었다 -> A=철수,P=영희,I=꽃,L=강단

어휘적관계 - 동의관계,반의관계,상하관계,원형,다의어,환유어,연어 등

화용론
언어사용자와 발화 맥락(Context)를 고려, 언어를 해석할 때 직역뿐 아니라 맥락을 고려함.
(어제 야구경기 어땠어 -> 발화자가 전날 야구 경기를 보았음을 전제함.)
화행
언어를 통해 이루어지는 행위 (다음주 이시간에 봅시다 -> 약속의 행위포함 행위는 약속,사과,충고,선언 등)
직접화행,간접화행 -> 문 좀 열어줘, 방이 너무 덥지 않냐?
언어사용에서의 협력원칙 (Paul Grice)
대화시 필요한 만큼의 정보,신뢰성 및 관련성이 있는 정확한 정보를 주고 받아야 함
- 양의원칙,질의원칙,관련성의원칙,태도의원칙


조건부 확률
a사건이 일어났다는 가정하에 b사건이 일어날 확률
P(B|A) = P(A교B) / P(A) 만일 해당 값이 P(B) 라면 A와 B는 독립이라고 함 즉
P(B|A) = P(A교B) / P(A) = P(B) -> P(B)P(A) = P(A교B) 임

연쇄규칙
사건이 3개 이상인 경우의 조건부확률
𝑃(𝐴∩𝐵∩𝐶)=𝑃(𝐴)𝑃(𝐵|𝐴)𝑃(𝐶|𝐴∩𝐵)
𝑃(𝐴1∩⋯∩𝐴𝑛)=𝑃(𝐴1)𝑃(𝐴2|𝐴1)⋯𝑃(𝐴𝑛|𝐴1∩𝐴2∩⋯∩𝐴𝑛−1)

베이즈 정리 - 확인필요
조건부 확률의 확장 표본공간이 b1~bn까지의 사상들로 구성(이때 모든 사상은 서로 겹치지 않게 분할됨.) 
어떤 사상 A를 계산 하는것.
𝑃(𝐴∩𝐵) = P(A)P(B|A) = P(B)P(A|B)

MLE(Maximum Likelihood Estimation(MLE))
MAP(Maximum a Posteriori Estimation(MAP)) -둘다 다시공부(인터넷)

엔트로피 - 확인필요
정보량은 확률이 높을수록 정보량은 적음
확률I(X) = log2(1/p(x))=-log2p(x) 
확률변수 X의 표본공간에서 나타나는 모든 사상들의 정보량의 평균 기댓값
값이 높을수록 불확실함 
H(X)=E[I(X)]


